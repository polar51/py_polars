import polars as pl
import os

# ==========================================
# 1. [ê³µí†µ] ë°ì´í„° ì „ì²˜ë¦¬
# ==========================================
def preprocess_lazy_frame(file_path: str) -> pl.LazyFrame:
    try:
        # infer_schema_length=0: ëª¨ë“  ì»¬ëŸ¼ì„ ì¼ë‹¨ ë¬¸ìë¡œ ì½ì–´ì„œ íƒ€ì… ì—ëŸ¬ ë°©ì§€
        lf = pl.scan_csv(file_path, infer_schema_length=0)

        # 1. ë‚ ì§œ ë° ìˆ˜ì¹˜í˜• ë³€í™˜
        lf = lf.with_columns([
            pl.col("oper_datetime").str.to_datetime(),
            pl.col("fleet_id").cast(pl.String),
            pl.col("car1_value").cast(pl.Float64),
            pl.col("car8_value").cast(pl.Float64),
        ])

        # 2. car1, car8 ë‘˜ ë‹¤ 0.02 ë„˜ëŠ” ë¡œìš°ë§Œ ë‚¨ê¹€
        lf = lf.filter(
            (pl.col("car1_value") > 0.02) &
            (pl.col("car8_value") > 0.02)
        )

        # 3. ë°ì´í„° í˜•íƒœ ë³€í™˜
        lf = lf.unpivot(
            index=["oper_datetime", "fleet_id"],  # ê³ ì •í•  ì»¬ëŸ¼ (id_vars)
            on=["car1_value", "car8_value"],      # í•©ì¹  ì»¬ëŸ¼ (value_vars)
            variable_name="car_source",
            value_name="value"
        )

        # 4. car_source ë¬¸ìì—´ì„ ìˆ«ì(1, 8)ë¡œ ë³€í™˜
        lf = lf.with_columns(
            pl.when(pl.col("car_source") == "car1_value")
            .then(1)
            .otherwise(8)
            .cast(pl.Int8)
            .alias("car_no")
        ).drop("car_source")

        return lf

    except Exception as e:
        print(f"ì „ì²˜ë¦¬ ì´ˆê¸°í™” ì¤‘ ì—ëŸ¬: {e}")
        raise e


# ==========================================
# 2. [ì•Œê³ ë¦¬ì¦˜ A] ê³¼ì „ë¥˜ ë° ê³¼ë¶€í•˜ ê²€ì§€
# ==========================================
def algo_a_overcurrent(lf: pl.LazyFrame) -> pl.LazyFrame:
    """ 3-1-1. ê³¼ì „ë¥˜ (1160 Â± 5%) """
    target = 1160
    lower = target * 0.95
    upper = target * 1.05

    return (
        lf.filter(pl.col("value") > 1000)
        .filter(pl.col("value").is_between(lower, upper))
        .select([
            pl.col("oper_datetime"),
            pl.col("fleet_id"),
            pl.col("car_no"),
            pl.lit("ê³¼ì „ë¥˜ ê²€ì§€").alias("event_no")
        ])
    )

def algo_a_overload(lf: pl.LazyFrame) -> pl.DataFrame:
    """ 3-1-2. ê³¼ë¶€í•˜ (547 Â± 5%, 1ì‹œê°„ ì—°ì†) """
    target = 547
    lower = target * 0.95
    upper = target * 1.05

    filtered_lf = lf.filter(
        (pl.col("value") <= 1000) &
        (pl.col("value").is_between(lower, upper))
    )

    try:
        df = filtered_lf.collect(engine="streaming")
    except:
        df = filtered_lf.collect()

    # ë¹ˆ ë°ì´í„°ì¼ ê²½ìš° ìŠ¤í‚¤ë§ˆ ì •ì˜ (fleet_idëŠ” Stringìœ¼ë¡œ í†µì¼)
    if df.is_empty():
        return pl.DataFrame(schema={
            "oper_datetime": pl.Datetime,
            "fleet_id": pl.String,      # <--- [í™•ì¸] ì—¬ê¸°ë„ String
            "car_no": pl.Int8,
            "event_no": pl.String
        })

    df = df.sort(["fleet_id", "car_no", "oper_datetime"])

    # 1ì‹œê°„ ì—°ì†ì„± ì²´í¬ (Gap: 10ë¶„)
    gap_threshold_seconds = 600

    df = df.with_columns([
        (pl.col("oper_datetime").diff().dt.total_seconds().fill_null(0) > gap_threshold_seconds)
        .over(["fleet_id", "car_no"])
        .cum_sum()
        .alias("session_id")
    ])

    result = (
        df.group_by(["fleet_id", "car_no", "session_id"])
        .agg([
            pl.col("oper_datetime").min().alias("start_time"),
            pl.col("oper_datetime").max().alias("end_time"),
            pl.col("oper_datetime").count().alias("cnt")
        ])
        .with_columns(
            (pl.col("end_time") - pl.col("start_time")).dt.total_seconds().alias("duration")
        )
        .filter(pl.col("duration") >= 3600)
    )

    return result.select([
        pl.col("start_time").alias("oper_datetime"),
        pl.col("fleet_id"),
        pl.col("car_no"),
        pl.lit("ê³¼ë¶€í•˜ ê²€ì§€").alias("event_no")
    ])


# ==========================================
# 3. [ì•Œê³ ë¦¬ì¦˜ B] ì´ìƒ ì „ë¥˜ ê²€ì§€ (í†µê³„)
# ==========================================
def algo_b_anomaly(lf: pl.LazyFrame) -> pl.LazyFrame:
    """
    4-1. í†µê³„ì  ì´ìƒì¹˜
    - ë‚˜ë¥¼ ì œì™¸í•œ í‰ê· ë³´ë‹¤ 25% ì´ìƒ í° ê²½ìš°ë§Œ ê²€ì¶œ
    - ê³µì‹: (ë‚´ê°’ - í‰ê· ) / í‰ê·  > 0.25
    """
    return (
        lf.with_columns([
            # 1. ê·¸ë£¹ë³„ í•©ê³„ì™€ ê°œìˆ˜ êµ¬í•˜ê¸°
            pl.col("value").sum().over(["fleet_id", "car_no"]).alias("grp_sum"),
            pl.col("value").count().over(["fleet_id", "car_no"]).alias("grp_cnt")
        ])
        .with_columns(
            # 2. ë‚˜ë¥¼ ì œì™¸í•œ(Leave-One-Out) í‰ê·  ê³„ì‚°
            ((pl.col("grp_sum") - pl.col("value")) / (pl.col("grp_cnt") - 1)).alias("loo_mean")
        )
        # í‰ê· ì´ ì—†ê±°ë‚˜ 0ì¸ ê²½ìš° ì œì™¸ (ë‚˜ëˆ„ê¸° 0 ë°©ì§€)
        .filter(pl.col("loo_mean").is_not_null() & (pl.col("loo_mean") != 0))
        .filter(
            # [ìˆ˜ì •ëœ ë¶€ë¶„] .abs()ë¥¼ ì œê±°í•˜ì—¬ ì–‘ì˜ ë°©í–¥(í° ê²½ìš°)ë§Œ ì²´í¬
            # ë‚´ ê°’ì´ í‰ê· ë³´ë‹¤ 25% ì´ˆê³¼í•˜ì—¬ í° ê²½ìš°
            ((pl.col("value") - pl.col("loo_mean")) / pl.col("loo_mean")) > 0.25
        )
        .select([
            pl.col("oper_datetime"),
            pl.col("fleet_id"),
            pl.col("car_no"),
            pl.lit("ì´ìƒ ì „ë¥˜ ê²€ì§€").alias("event_no")
        ])
    )


# ==========================================
# 4. ì‹¤í–‰ë¶€ (Main)
# ==========================================
if __name__ == "__main__":
    csv_file = "siv_Inverter.csv"

    if not os.path.exists(csv_file):
        print(f"ì˜¤ë¥˜: '{csv_file}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        exit()

    print(f">>> '{csv_file}' ë°ì´í„° ì²˜ë¦¬ ì‹œì‘...")

    base_lf = preprocess_lazy_frame(csv_file)

    print("- SIV ì¶œë ¥ì „ë¥˜ ê³¼ì „ë¥˜ ë¶„ì„ ì¤‘...")
    res_a1 = algo_a_overcurrent(base_lf).collect(engine="streaming")

    print("- SIV ì¶œë ¥ì „ë¥˜ ê³¼ë¶€í•˜-ì‹œê°„ì—°ì† ë¶„ì„ ì¤‘...")
    res_a2 = algo_a_overload(base_lf)

    print("- SIV ì¶œë ¥ì „ë¥˜ ì´ìƒì „ë¥˜ ë¶„ì„ ì¤‘...")
    res_b = algo_b_anomaly(base_lf).collect(engine="streaming")

    # ê²°ê³¼ í•©ì¹˜ê¸°
    final_df = pl.concat([res_a1, res_a2, res_b])

    # ---------------------------------------------------------
    # [ìˆ˜ì •] ë¯¸ë¦¬ë³´ê¸° ëŒ€ì‹  ì•Œê³ ë¦¬ì¦˜ë³„ ê±´ìˆ˜ ìš”ì•½ ì¶œë ¥
    # ---------------------------------------------------------
    count_a1 = len(res_a1)
    count_a2 = len(res_a2)
    count_b = len(res_b)
    total_count = len(final_df)

    print("\n" + "="*40)
    print("       ğŸ“Š ë°ì´í„° ë¶„ì„ ê²°ê³¼ ìš”ì•½")
    print("="*40)
    print(f" 1. SIV ì¶œë ¥ì „ë¥˜ ê³¼ì „ë¥˜   : {count_a1:>5} ê±´")
    print(f" 2. SIV ì¶œë ¥ì „ë¥˜ ê³¼ë¶€í•˜   : {count_a2:>5} ê±´")
    print(f" 3. SIV ì¶œë ¥ì „ë¥˜ ì´ìƒì „ë¥˜ : {count_b:>5} ê±´")
    print("-" * 40)
    print(f"    ì´ ì´ë²¤íŠ¸ ë°œìƒ ê±´ìˆ˜     : {total_count:>5} ê±´")
    print("="*40)

    # ë°ì´í„°ê°€ ìˆì„ ê²½ìš°ì—ë§Œ íŒŒì¼ ì €ì¥
    if not final_df.is_empty():
        # ë‚ ì§œìˆœ ì •ë ¬ ë° ë¬¸ìì—´ ë³€í™˜
        final_df = final_df.sort("oper_datetime")

        result_list = final_df.with_columns(
            pl.col("oper_datetime").dt.to_string("%Y-%m-%d %H:%M:%S")
        ).to_dicts()

        output_file = "result_events.txt"
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(str(result_list))

        print(f"\n>>> ìƒì„¸ ë°ì´í„°ê°€ '{output_file}' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("\n>>> ì¡°ê±´ì— ë§ëŠ” ì´ë²¤íŠ¸ê°€ í•˜ë‚˜ë„ ê²€ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")